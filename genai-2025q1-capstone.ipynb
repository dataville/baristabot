{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-3-building-an-agent-with-langgraph.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"cellView":"form","id":"d6597b11df14","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:25:31.792753Z","iopub.execute_input":"2025-04-18T05:25:31.793209Z","iopub.status.idle":"2025-04-18T05:25:31.821307Z","shell.execute_reply.started":"2025-04-18T05:25:31.793170Z","shell.execute_reply":"2025-04-18T05:25:31.820050Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# BaristaBot: AI-Powered Cafe Ordering System\n\n## The Problem: Streamlining Cafe Ordering Experiences\n\nTraditional cafe ordering systems face several challenges:\n\n- They often lack the natural conversational flow that customers prefer\n- Menu information may be scattered or difficult to search\n- Ordering complex drinks with multiple modifiers can be confusing\n- Order confirmation and validation are frequently manual processes\n- Customer service quality can be inconsistent depending on staff availability\n\n## How Generative AI Solves This\n\nThis notebook demonstrates a powerful solution through **BaristaBot**, an interactive cafe ordering system powered by:\n\n1. **LangGraph** for creating a multi-step conversational workflow\n2. **Google's Gemini model** for natural language understanding\n3. **Vector databases** for intelligent menu search and retrieval\n\nThe system showcases how generative AI can:\n\n- Engage in natural dialog about menu items and their details\n- Maintain contextual awareness throughout the ordering process\n- Dynamically search and retrieve menu information using semantic understanding\n- Process complex orders with modifiers (milk types, sweeteners, temperature preferences)\n- Validate its own responses for accuracy before presenting to customers\n- Confirm orders explicitly with customers before processing\n\nThis implementation demonstrates how AI can transform customer service in food service settings by combining the convenience of digital ordering with the natural feel of human conversation, all while maintaining accuracy and consistency.","metadata":{}},{"cell_type":"markdown","source":"## Project Overview\n\nThis capstone project enhances the original BaristaBot from the 5-Day Gen AI Intensive Course by implementing advanced AI techniques to create a more intelligent and responsive cafe ordering system.\n\n## Original Source & Attribution\n\n- **Course**: [5-Day Gen AI Intensive Course with Google Learn Guide](https://www.kaggle.com/learn-guide/5-day-genai)\n- **Original Code**: [Day 3 - Building an Agent with LangGraph](https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph/)\n- **Course Developers**: Addison Howard, Brenda Flynn, Myles O'Neill, Nate, and Polong Lin\n- **Competition**: [Gen AI Intensive Course Capstone 2025Q1](https://kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1)\n\n## Technical Enhancements & Implementation\n\nThe system leverages these core technologies and improvements:\n\n### 1. Vector Database with FAISS\n- Replaces hardcoded menu with dynamic, searchable vector database\n- Enables semantic search across menu items and categories\n- Provides scalability for menu updates without code changes\n\n### 2. Retrieval Augmented Generation (RAG)\n- Dynamically retrieves relevant menu information based on customer queries\n- Delivers contextual responses about drink options and modifiers\n- Supports natural language search for menu information\n\n### 3. LLM-Based Quality Control\n- Evaluates responses before presentation to customers\n- Automatically corrects responses that don't meet quality standards\n- Ensures consistent adherence to menu options and clear communication\n\n## Project Significance\n\nThis implementation demonstrates how combining LangGraph, Gemini AI, vector search, and evaluation systems can transform customer service applications by creating more accurate, natural, and adaptable conversational experiences in real-world business settings.","metadata":{}},{"cell_type":"markdown","source":"## Get set up\n\nStart by installing and importing the LangGraph SDK and LangChain support for the Gemini API.","metadata":{"id":"aKMOcAKnGBPL"}},{"cell_type":"code","source":"# Remove conflicting packages from the Kaggle base environment.\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n# Install langgraph and the packages used in this lab.\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7' 'langchain_community' 'faiss-cpu'","metadata":{"id":"04fZ8d37ifOS","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:25:38.018305Z","iopub.execute_input":"2025-04-18T05:25:38.018732Z","iopub.status.idle":"2025-04-18T05:26:29.442074Z","shell.execute_reply.started":"2025-04-18T05:25:38.018696Z","shell.execute_reply":"2025-04-18T05:26:29.440381Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Set up your API key\n\nThe `GOOGLE_API_KEY` environment variable can be set to automatically configure the underlying API. This works for both the official Gemini Python SDK and for LangChain/LangGraph. \n\nTo run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n\nIf you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{"id":"GecNc73VGfpk"}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"id":"xaiioUQni_ga","execution":{"iopub.status.busy":"2025-04-18T05:26:29.444402Z","iopub.execute_input":"2025-04-18T05:26:29.444782Z","iopub.status.idle":"2025-04-18T05:26:29.577835Z","shell.execute_reply.started":"2025-04-18T05:26:29.444745Z","shell.execute_reply":"2025-04-18T05:26:29.576609Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from typing import Annotated\nfrom typing_extensions import TypedDict\nfrom typing import Literal\nfrom typing import Iterable\n\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, START, END\n\nfrom langchain_core.messages.ai import AIMessage\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_core.tools import tool\nfrom langchain_core.messages.tool import ToolMessage\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nfrom collections.abc import Iterable\nfrom random import randint\n\nfrom pprint import pprint, PrettyPrinter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:26:37.266557Z","iopub.execute_input":"2025-04-18T05:26:37.266922Z","iopub.status.idle":"2025-04-18T05:26:39.259992Z","shell.execute_reply.started":"2025-04-18T05:26:37.266892Z","shell.execute_reply":"2025-04-18T05:26:39.259039Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# State Management in BaristaBot\n\nIn this section, we define the core state structure and system instructions for our BaristaBot application. Let's examine how LangGraph manages conversation state:\n\n## OrderState Class\n\nThis class is the foundation of our application. Let's break down each component:\n\n### TypedDict\n- This Python feature provides static type hints for dictionaries with a fixed set of keys, making our code more maintainable.\n\n### messages\n- Stores the entire conversation history\n- The `Annotated[list, add_messages]` syntax is crucial - it tells LangGraph to append new messages rather than replacing the entire list\n- Without this annotation, each node would override previous messages instead of building a conversation\n\n### order\n- A simple list of strings representing ordered items\n- Each string contains both the drink and its modifiers (e.g., \"Latte (oat milk, vanilla)\")\n\n### finished\n- Boolean flag indicating when to terminate the conversation\n- Set to True when order is placed or user quits\n\n## The BARISTABOT_SYSINT tuple \n\nThis tuple contains system instructions that define the LLM's behavior:\n\n### Key aspects of these instructions:\n\n#### Role Definition\n- Establishes the bot's identity and purpose\n\n#### Conversation Boundaries\n- Restricts discussion to menu items and products\n\n#### Tool Usage Guidelines\n- Defines when and how to use various functions:\n  * `get_menu` and `search_menu` for accessing menu information\n  * `add_to_order`, `clear_order`, `get_order` for order management\n  * `confirm_order` for verification\n  * `place_order` for completion\n\n#### Quality Standards\n- Mentions the evaluation process for responses\n\n#### Fallback Behavior\n- Instructions for handling unavailable tools\n\n## The welcome message \n\n`WELCOME_MSG` provides the initial greeting and exit instructions.\n\n## Why This Matters\n\nThis approach to state management offers several benefits:\n* **Persistence**: Conversation history is maintained across different processing nodes\n* **Modularity**: Separating state from logic makes the system easier to extend\n* **Clarity**: Type hints improve code readability and help catch errors early","metadata":{}},{"cell_type":"code","source":"class OrderState(TypedDict):\n    \"\"\"State representing the customer's order conversation.\"\"\"\n\n    # The chat conversation. This preserves the conversation history\n    # between nodes. The `add_messages` annotation indicates to LangGraph\n    # that state is updated by appending returned messages, not replacing\n    # them.\n    messages: Annotated[list, add_messages]\n\n    # The customer's in-progress order.\n    order: list[str]\n\n    # Flag indicating that the order is placed and completed.\n    finished: bool\n\n\n# The system instruction defines how the chatbot is expected to behave and includes\n# rules for when to call different functions, as well as rules for the conversation, such\n# as tone and what is permitted for discussion.\nBARISTABOT_SYSINT = (\n    \"system\",  # 'system' indicates the message is a system instruction.\n    \"You are a BaristaBot, an interactive cafe ordering system. A human will talk to you about the \"\n    \"available products you have and you will answer any questions about menu items (and only about \"\n    \"menu items - no off-topic discussion, but you can chat about the products and their history). \"\n    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n    \"and send to the ordering system after confirming the order with the human. \"\n    \"\\n\\n\"\n    \"You have access to an up-to-date menu database. Use get_menu to retrieve the full menu, and \"\n    \"search_menu with a specific query to find detailed information about particular items, modifiers, \"\n    \"or categories. Always use these tools when you need menu information rather than relying on your \"\n    \"general knowledge about coffee drinks.\"\n    \"\\n\\n\"\n    \"Add items to the customer's order with add_to_order, and reset the order with clear_order. \"\n    \"To see the contents of the order so far, call get_order (this is shown to you, not the user) \"\n    \"Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will \"\n    \"display the order items to the user and returns their response to seeing the list. Their response may contain modifications. \"\n    \"Always verify and respond with drink and modifier names from the MENU before adding them to the order. \"\n    \"If you are unsure a drink or modifier matches those on the MENU, use search_menu to confirm availability before adding to the order. \"\n    \"You only have the modifiers listed on the menu. \"\n    \"Once the customer has finished ordering items, Call confirm_order to ensure it is correct then make \"\n    \"any necessary updates and then call place_order. Once place_order has returned, thank the user and \"\n    \"say goodbye!\"\n    \"\\n\\n\"\n    \"Remember that your responses will be evaluated before reaching the user to ensure they: \"\n    \"1. Correctly follow menu options \"\n    \"2. Use appropriate tools for ordering \"\n    \"3. Stay on-topic about cafe items only \"\n    \"4. Are helpful and clear for customers \"\n    \"\\n\\n\"\n    \"If any of the tools are unavailable, you can break the fourth wall and tell the user that \"\n    \"they have not implemented them yet and should keep reading to do so.\",\n)\n\n# This is the message with which the system opens the conversation.\nWELCOME_MSG = \"Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\"","metadata":{"id":"2RJQRlfVjqkJ","execution":{"iopub.status.busy":"2025-04-18T05:26:43.258384Z","iopub.execute_input":"2025-04-18T05:26:43.258964Z","iopub.status.idle":"2025-04-18T05:26:43.267616Z","shell.execute_reply.started":"2025-04-18T05:26:43.258926Z","shell.execute_reply":"2025-04-18T05:26:43.266384Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## LLM Initialization:\n\nWe create an instance of the Google Generative AI chat model\nSpecifically, we're using gemini-2.0-flash, Google's optimized model for fast responses\n","metadata":{"id":"PHkDsSI_NUp7"}},{"cell_type":"code","source":"llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n","metadata":{"id":"Y359hoepjv6i","execution":{"iopub.status.busy":"2025-04-18T05:26:48.276830Z","iopub.execute_input":"2025-04-18T05:26:48.277259Z","iopub.status.idle":"2025-04-18T05:26:48.353370Z","shell.execute_reply.started":"2025-04-18T05:26:48.277195Z","shell.execute_reply":"2025-04-18T05:26:48.352446Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Understanding the human_node Function\n\n### Function Purpose\nThe human_node function is responsible for handling the human side of the conversation in this BaristaBot application. It's a critical component that:\n* Shows the AI's message to the user\n* Collects the user's response\n* Processes any exit commands\n* Updates the conversation state\n\n### Function Parameters and Return Value\n* Input: Takes a parameter `state` of type `OrderState` (a TypedDict that stores conversation history and order information)\n* Output: Returns an updated `OrderState` with the user's new message added","metadata":{}},{"cell_type":"code","source":"def human_node(state: OrderState) -> OrderState:\n    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n    last_msg = state[\"messages\"][-1]\n    print(\"Model:\", last_msg.content)\n\n    user_input = input(\"User: \")\n\n    # If it looks like the user is trying to quit, flag the conversation\n    # as over.\n    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n        state[\"finished\"] = True\n\n    return state | {\"messages\": [(\"user\", user_input)]}\n\n\n","metadata":{"id":"UtOpn68ospVj","execution":{"iopub.status.busy":"2025-04-18T05:26:51.106004Z","iopub.execute_input":"2025-04-18T05:26:51.106454Z","iopub.status.idle":"2025-04-18T05:26:51.115358Z","shell.execute_reply.started":"2025-04-18T05:26:51.106416Z","shell.execute_reply":"2025-04-18T05:26:51.113998Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Understanding the maybe_exit_human_node Function\n\nThis function serves as a crucial routing decision point in the BaristaBot conversation flow:\n\n### Function Purpose\nThe maybe_exit_human_node function determines where the conversation should flow after the user has provided input. It acts as a conditional router that decides whether to:\n* Continue the conversation by proceeding to the chatbot node\n* End the conversation entirely\n\n### Function Signature\n* Input: Takes a parameter `state` of type `OrderState`\n* Output: Returns a string literal that can be either \"chatbot\" or \"__end__\" (represented by the constant `END`)\n\n### Decision Logic\nThe function contains a simple conditional check:\n```python\nif state.get(\"finished\", False):\n    return END\nelse:\n    return \"chatbot\"\n```\n\nThis checks if the `finished` flag in the state dictionary is True:\n* If True, the function returns `END`, which signals to LangGraph that the conversation should terminate\n* If False, it returns \"chatbot\", which routes the flow to the chatbot node to generate the next AI response\n\nThe `.get(\"finished\", False)` method safely retrieves the value of the \"finished\" key with a default of False if the key doesn't exist.\n\n### In the LangGraph Context\nIn the overall application, this function is used as a conditional edge in the state graph:\n```python\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n```\n\nThis tells LangGraph to use the return value of `maybe_exit_human_node` to determine where to route the state after it passes through the `human_node`. The routing is based on the value of the `finished` flag, which is set to True in `human_node` when the user types an exit command like \"q\", \"quit\", \"exit\", or \"goodbye\".","metadata":{}},{"cell_type":"code","source":"def maybe_exit_human_node(state: OrderState) -> Literal[\"chatbot\", \"__end__\"]:\n    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n    if state.get(\"finished\", False):\n        return END\n    else:\n        return \"chatbot\"","metadata":{"id":"6468OAgSU2He","execution":{"iopub.status.busy":"2025-04-18T05:26:55.241586Z","iopub.execute_input":"2025-04-18T05:26:55.241987Z","iopub.status.idle":"2025-04-18T05:26:55.247660Z","shell.execute_reply.started":"2025-04-18T05:26:55.241951Z","shell.execute_reply":"2025-04-18T05:26:55.246504Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# The default recursion limit for traversing nodes is 25 - setting it higher means\n# you can try a more complex order with multiple steps and round-trips (and you\n# can chat for longer!)\nconfig = {\"recursion_limit\": 100}\n","metadata":{"id":"udGNmyasTGJG","execution":{"iopub.status.busy":"2025-04-18T05:26:56.906333Z","iopub.execute_input":"2025-04-18T05:26:56.906718Z","iopub.status.idle":"2025-04-18T05:26:56.911455Z","shell.execute_reply.started":"2025-04-18T05:26:56.906684Z","shell.execute_reply":"2025-04-18T05:26:56.910390Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Building a Vector Database for the Cafe Menu\n\nBaristaBot currently has no awareness of the available items at the cafe, so it will hallucinate a menu. One option would be to hard-code a menu into the system prompt. A better option would be to provide searchable vector database that can easily be updated.\n        \nThis code creates a searchable vector database containing the cafe's menu items, allowing the BaristaBot to quickly find relevant menu information based on natural language queries:\n\n### What This Function Does\n\nThe `initialize_menu_db()` function creates a searchable knowledge base of the cafe's menu by:\n\n1. **Structuring the menu as documents**:\n   Each menu section becomes a Document object with:\n   * `page_content`: The actual text describing menu items\n   * `metadata`: Categorization information (like \"Coffee\", \"Tea\", \"Modifiers\")\n\n2. **Organizing menu information into categories**:\n   * Basic drink types (Coffee, Tea, Other)\n   * Drinks with milk additions\n   * Available modifiers (milk types, espresso shots, sweeteners)\n   * Special terminology and rules\n   * Detailed descriptions of popular drinks\n\n3. **Creating vector embeddings**: Using Google's AI embeddings model to convert menu text into numerical vector representations that capture semantic meaning\n\n4. **Building a FAISS vector store**: Creating an efficient similarity search database that can find the most relevant menu items based on natural language queries\n\n### Why This Matters\n\nThis vector database enables the BaristaBot to:\n* Answer questions about what drinks are available\n* Find specific information about drink ingredients and preparation\n* Understand what customization options are available\n* Process natural language queries without requiring exact keyword matching\n* Maintain an up-to-date menu without hardcoding it into the application logic\n\nThe vector store is queried by the `get_menu()` and `search_menu()` tools later in the application, allowing the AI assistant to provide accurate and relevant menu information to customers.","metadata":{}},{"cell_type":"code","source":"# Create a global vector database for the menu\ndef initialize_menu_db():\n    # Split menu into documents - one for each section/item\n    menu_docs = [\n        Document(page_content=\"Coffee Drinks: Espresso, Americano, Cold Brew\", \n                 metadata={\"category\": \"Coffee\"}),\n        Document(page_content=\"Coffee Drinks with Milk: Latte, Cappuccino, Cortado, Macchiato, Mocha, Flat White\", \n                 metadata={\"category\": \"Coffee with Milk\"}),\n        Document(page_content=\"Tea Drinks: English Breakfast Tea, Green Tea, Earl Grey\", \n                 metadata={\"category\": \"Tea\"}),\n        Document(page_content=\"Tea Drinks with Milk: Chai Latte, Matcha Latte, London Fog\", \n                 metadata={\"category\": \"Tea with Milk\"}),\n        Document(page_content=\"Other Drinks: Steamer, Hot Chocolate\", \n                 metadata={\"category\": \"Other\"}),\n        Document(page_content=\"Milk options: Whole, 2%, Oat, Almond, 2% Lactose Free; Default option: whole\", \n                 metadata={\"category\": \"Modifiers\"}),\n        Document(page_content=\"Espresso shots: Single, Double, Triple, Quadruple; default: Double\", \n                 metadata={\"category\": \"Modifiers\"}),\n        Document(page_content=\"Caffeine: Decaf, Regular; default: Regular\", \n                 metadata={\"category\": \"Modifiers\"}),\n        Document(page_content=\"Hot-Iced: Hot, Iced; Default: Hot\", \n                 metadata={\"category\": \"Modifiers\"}),\n        Document(page_content=\"Sweeteners: vanilla sweetener, hazelnut sweetener, caramel sauce, chocolate sauce, sugar free vanilla sweetener\", \n                 metadata={\"category\": \"Modifiers\"}),\n        Document(page_content=\"Special terms: 'dirty' means add a shot of espresso to a drink that doesn't usually have it\", \n                 metadata={\"category\": \"Special\"}),\n        Document(page_content=\"Milk terms: 'Regular milk' is the same as 'whole milk'\", \n                 metadata={\"category\": \"Special\"}),\n        Document(page_content=\"Sweetener terms: 'Sweetened' means add regular sugar, not a flavored sweetener\",\n                 metadata={\"category\": \"Special\"}),\n        Document(page_content=\"Availability: Soy milk has run out of stock today, so soy is not available\",\n                 metadata={\"category\": \"Special\"}),\n        # Add detailed descriptions for popular drinks\n        Document(page_content=\"Latte: Espresso with steamed milk and a light layer of foam. Flavors can be added.\",\n                 metadata={\"category\": \"Drink Details\", \"item\": \"Latte\"}),\n        Document(page_content=\"Cappuccino: Equal parts espresso, steamed milk, and foam for a stronger coffee taste.\",\n                 metadata={\"category\": \"Drink Details\", \"item\": \"Cappuccino\"}),\n        Document(page_content=\"Chai Latte: Spiced black tea concentrate mixed with steamed milk.\",\n                 metadata={\"category\": \"Drink Details\", \"item\": \"Chai Latte\"}),\n    ]\n    \n    # Create embeddings and vector store\n    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n    return FAISS.from_documents(menu_docs, embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:00.859482Z","iopub.execute_input":"2025-04-18T05:27:00.859835Z","iopub.status.idle":"2025-04-18T05:27:00.869698Z","shell.execute_reply.started":"2025-04-18T05:27:00.859805Z","shell.execute_reply":"2025-04-18T05:27:00.868488Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Initialize the vector store once\nmenu_db = initialize_menu_db()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:03.216007Z","iopub.execute_input":"2025-04-18T05:27:03.216414Z","iopub.status.idle":"2025-04-18T05:27:03.953183Z","shell.execute_reply.started":"2025-04-18T05:27:03.216377Z","shell.execute_reply":"2025-04-18T05:27:03.952013Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## The get_menu() Tool Function Explained\n\nThis function creates a structured menu display by retrieving and organizing menu items from the vector database:\n\n### Function Overview\n\nThe `get_menu()` function is labeled with the `@tool` decorator, which registers it as a callable tool that the LLM can use during conversations with customers. This function retrieves and formats the entire cafe menu in a readable format.\n\n### Key Components\n\n1. **Function Decoration**:\n   - The `@tool` decorator makes this function available to the LLM as a named tool that can be invoked during conversation\n\n2. **Vector Database Query**:\n   - `retriever = menu_db.as_retriever(search_kwargs={\"k\": 10})` creates a retriever that will return up to 10 matching documents\n   - `docs = retriever.invoke(\"all menu categories\")` queries the database for menu items across all categories\n\n3. **Menu Organization**:\n   - The function initializes an empty dictionary to group menu items by category\n   - It iterates through each retrieved document and organizes them by their category metadata\n   - If a category doesn't exist in the dictionary yet, it creates a new list for that category\n\n4. **Menu Formatting**:\n   - The function builds a well-formatted string containing the entire menu\n   - Items are grouped by category, making the menu easier to read and understand\n   - Each category's items are joined with newlines and separated by blank lines\n\n### Why This Matters\n\nThis function serves as the BaristaBot's knowledge source for the complete menu, allowing it to:\n* Provide customers with the full menu when requested\n* Answer general questions about what's available\n* Stay up-to-date with menu changes (as the vector database can be updated)\n* Present menu information in a structured, user-friendly format\n\nWhen a customer asks something like \"What do you have?\" or \"Can I see the menu?\", the LLM can call this function to retrieve the complete, organized menu to share with the customer.","metadata":{}},{"cell_type":"code","source":"@tool\ndef get_menu() -> str:\n    \"\"\"Provide the latest up-to-date menu from our menu database.\"\"\"\n    # Get all menu categories\n    retriever = menu_db.as_retriever(search_kwargs={\"k\": 10})\n    # Use invoke instead of get_relevant_documents\n    docs = retriever.invoke(\"all menu categories\")\n    \n    # Build a formatted menu from retrieved documents\n    menu_text = \"MENU:\\n\"\n    \n    # Group documents by category\n    categories = {}\n    for doc in docs:\n        category = doc.metadata.get(\"category\", \"Other\")\n        if category not in categories:\n            categories[category] = []\n        categories[category].append(doc.page_content)\n    \n    # Format the menu\n    for category, items in categories.items():\n        menu_text += \"\\n\".join(items) + \"\\n\\n\"\n        \n    return menu_text","metadata":{"id":"hG1n6mNFHsYW","execution":{"iopub.status.busy":"2025-04-18T05:27:06.312423Z","iopub.execute_input":"2025-04-18T05:27:06.312837Z","iopub.status.idle":"2025-04-18T05:27:06.326630Z","shell.execute_reply.started":"2025-04-18T05:27:06.312802Z","shell.execute_reply":"2025-04-18T05:27:06.325350Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## The search_menu Tool Function Explained\n\nThis function creates a specialized menu search capability that lets the BaristaBot find specific information:\n\n### Function Purpose\nWhile `get_menu()` retrieves the entire menu, `search_menu()` allows for targeted searches to answer specific customer questions about menu items, ingredients, or options.\n\n### Key Components\n1. **Tool Registration**:\n   - The `@tool` decorator registers this function as a tool that the LLM can invoke during conversations\n   - The function signature shows it takes a string query and returns a string result\n\n2. **Focused Retrieval**:\n   - `retriever = menu_db.as_retriever(search_kwargs={\"k\": 3})` creates a retriever limited to the 3 most relevant results\n   - This prevents overwhelming customers with too much information\n\n3. **Semantic Search**:\n   - `docs = retriever.invoke(query)` performs a semantic search using the query string\n   - This allows natural language questions like \"What milk options do you have?\" or \"Tell me about your lattes\"\n\n4. **Error Handling**:\n   - The function handles the case where no relevant information is found\n   - It returns a clear message stating nothing was found for the query\n\n5. **Result Formatting**:\n   - The function formats the results with a clear header\n   - It includes all the content from each matching document in the response\n\n### Why This Matters\nThis function enables more natural conversation by allowing BaristaBot to:\n* Answer specific questions about menu items (\"What's in a chai latte?\")\n* Find available options for customization (\"What milk alternatives do you have?\")\n* Check if special requests are possible (\"Can I get a decaf cappuccino?\")\n* Provide detailed information without overwhelming the customer with the entire menu\n\nThis targeted search capability makes the BaristaBot more helpful and efficient, allowing customers to get exactly the information they need about specific menu items or options.","metadata":{}},{"cell_type":"code","source":"# Add an additional search_menu tool\n@tool\ndef search_menu(query: str) -> str:\n    \"\"\"Search for specific information in the menu database.\"\"\"\n    retriever = menu_db.as_retriever(search_kwargs={\"k\": 3})\n    # Use invoke instead of get_relevant_documents\n    docs = retriever.invoke(query)\n    \n    if not docs:\n        return f\"I couldn't find information about '{query}' in our menu.\"\n    \n    result = f\"Here's what I found about '{query}':\\n\\n\"\n    for doc in docs:\n        result += doc.page_content + \"\\n\"\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:10.548579Z","iopub.execute_input":"2025-04-18T05:27:10.548978Z","iopub.status.idle":"2025-04-18T05:27:10.560350Z","shell.execute_reply.started":"2025-04-18T05:27:10.548941Z","shell.execute_reply":"2025-04-18T05:27:10.559455Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Empty Tool Functions vs. Implementation\n\nThis code section showcases an important LangGraph pattern where tool interfaces are defined separately from their implementations:\n\n### The Pattern: Empty Function Bodies\n\nThese functions are intentionally defined with empty bodies because of a specific architectural constraint in LangGraph:\n\n* **Tool Registration**: The `@tool` decorator registers these functions as available tools for the LLM to call\n* **State Management Limitation**: LangGraph doesn't allow `@tool`-decorated functions to directly modify the conversation state\n* **Deferred Implementation**: The actual implementation of these functions is handled separately in the `order_node` function\n\n### Why This Approach Matters\n\nThis pattern creates a clean separation between:\n\n1. **Tool Definition**: The function signatures and docstrings create a clear interface that tells the LLM:\n   * What tools are available\n   * What parameters they take\n   * What they return\n   * What they're supposed to do\n\n2. **Tool Implementation**: The actual behavior is implemented elsewhere (in the `order_node`), where it can properly update the state\n\nThis separation is beneficial because:\n* It provides a clean API for the LLM to understand and use\n* It centralizes state-changing logic in dedicated nodes\n* It follows LangGraph's constraints around state management\n\n### The Order Management Tools\n\nThe five defined tools cover the complete order lifecycle:\n* `add_to_order`: Adds drinks with customizations to the order\n* `get_order`: Retrieves the current order contents\n* `confirm_order`: Asks the customer if the order is correct\n* `clear_order`: Removes all items from the order\n* `place_order`: Finalizes the order and provides wait time\n\nTogether, these tools enable the BaristaBot to manage the ordering process while maintaining a clean architectural separation between tool definition and state-changing implementation.","metadata":{}},{"cell_type":"code","source":"# These functions have no body; LangGraph does not allow @tools to update\n# the conversation state, so you will implement a separate node to handle\n# state updates. Using @tools is still very convenient for defining the tool\n# schema, so empty functions have been defined that will be bound to the LLM\n# but their implementation is deferred to the order_node.\n\n\n@tool\ndef add_to_order(drink: str, modifiers: Iterable[str]) -> str:\n    \"\"\"Adds the specified drink to the customer's order, including any modifiers.\n\n    Returns:\n      The updated order in progress.\n    \"\"\"\n\n\n@tool\ndef confirm_order() -> str:\n    \"\"\"Asks the customer if the order is correct.\n\n    Returns:\n      The user's free-text response.\n    \"\"\"\n\n\n@tool\ndef get_order() -> str:\n    \"\"\"Returns the users order so far. One item per line.\"\"\"\n\n\n@tool\ndef clear_order():\n    \"\"\"Removes all items from the user's order.\"\"\"\n\n\n@tool\ndef place_order() -> int:\n    \"\"\"Sends the order to the barista for fulfillment.\n\n    Returns:\n      The estimated number of minutes until the order is ready.\n    \"\"\"","metadata":{"id":"jqsLovPBQe0I","execution":{"iopub.status.busy":"2025-04-18T05:27:14.648188Z","iopub.execute_input":"2025-04-18T05:27:14.648608Z","iopub.status.idle":"2025-04-18T05:27:14.676658Z","shell.execute_reply.started":"2025-04-18T05:27:14.648575Z","shell.execute_reply":"2025-04-18T05:27:14.675345Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## The order_node Function: Implementing Order Management Logic\n\nThe `order_node` function is the core implementation of the BaristaBot's order management capabilities:\n\n### Function Purpose\nThis function provides the actual implementation for all the ordering tools that were previously defined with empty bodies. When the LLM decides to use an ordering tool, this function executes the appropriate logic and updates the conversation state.\n\n### Key Implementation Details\n\n1. **State Management**\n   * The function retrieves the current state (latest message and order list)\n   * It tracks whether an order has been placed\n   * It collects messages to be sent back\n\n2. **Tool Implementation**\n   For each tool call, the function implements specific behavior:\n\n   #### add_to_order\n   * Formats drink items with their modifiers (e.g., \"Latte (oat milk, vanilla)\")\n   * Adds the formatted item to the order list\n   * Returns the updated order as a string\n\n   #### confirm_order\n   * Displays the current order items directly to the customer\n   * Explicitly shows empty orders as \"(no items)\"\n   * Collects confirmation directly from the customer via input\n   * Important: Shows the exact order data to avoid AI hallucination issues\n\n   #### get_order\n   * Returns the formatted order or \"(no order)\" if empty\n   * Used by the LLM to check what's in the order without showing the customer\n\n   #### clear_order\n   * Empties the order list\n   * Returns no response (None)\n\n   #### place_order\n   * Displays the final order that's being sent to the kitchen\n   * Sets the order_placed flag to true\n   * Returns a random estimated wait time (1-5 minutes)\n\n3. **Response Handling**\n   * Creates a `ToolMessage` for each tool response\n   * Includes proper tool call IDs for response tracking\n   * Returns the updated state with new messages, order list, and completion status\n\n### Architecture Significance\nThis implementation demonstrates a key LangGraph pattern where:\n* Tools are defined with the `@tool` decorator (providing interface and documentation)\n* The actual implementation lives in a dedicated node that handles state updates\n* The results are formatted as tool messages that can be processed by the LLM\n\nThis separation maintains a clean architecture while allowing the LLM to use tools that modify the application state.","metadata":{}},{"cell_type":"code","source":"def order_node(state: OrderState) -> OrderState:\n    \"\"\"The ordering node. This is where the order state is manipulated.\"\"\"\n    tool_msg = state.get(\"messages\", [])[-1]\n    order = state.get(\"order\", [])\n    outbound_msgs = []\n    order_placed = False\n\n    for tool_call in tool_msg.tool_calls:\n\n        if tool_call[\"name\"] == \"add_to_order\":\n\n            # Each order item is just a string. This is where it assembled as \"drink (modifiers, ...)\".\n            modifiers = tool_call[\"args\"][\"modifiers\"]\n            modifier_str = \", \".join(modifiers) if modifiers else \"no modifiers\"\n\n            order.append(f'{tool_call[\"args\"][\"drink\"]} ({modifier_str})')\n            response = \"\\n\".join(order)\n\n        elif tool_call[\"name\"] == \"confirm_order\":\n\n            # We could entrust the LLM to do order confirmation, but it is a good practice to\n            # show the user the exact data that comprises their order so that what they confirm\n            # precisely matches the order that goes to the kitchen - avoiding hallucination\n            # or reality skew.\n\n            # In a real scenario, this is where you would connect your POS screen to show the\n            # order to the user.\n\n            print(\"Your order:\")\n            if not order:\n                print(\"  (no items)\")\n\n            for drink in order:\n                print(f\"  {drink}\")\n\n            response = input(\"Is this correct? \")\n\n        elif tool_call[\"name\"] == \"get_order\":\n            response = \"\\n\".join(order) if order else \"(no order)\"\n\n        elif tool_call[\"name\"] == \"clear_order\":\n\n            order.clear()\n            response = None\n\n        elif tool_call[\"name\"] == \"place_order\":\n\n            order_text = \"\\n\".join(order)\n            print(\"Sending order to kitchen!\")\n            print(order_text)\n\n            # TODO(you!): Implement cafe.\n            order_placed = True\n            response = randint(1, 5)  # ETA in minutes\n\n        else:\n            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n\n        # Record the tool results as tool messages.\n        outbound_msgs.append(\n            ToolMessage(\n                content=response,\n                name=tool_call[\"name\"],\n                tool_call_id=tool_call[\"id\"],\n            )\n        )\n\n    return {\"messages\": outbound_msgs, \"order\": order, \"finished\": order_placed}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:19.212938Z","iopub.execute_input":"2025-04-18T05:27:19.213752Z","iopub.status.idle":"2025-04-18T05:27:19.224142Z","shell.execute_reply.started":"2025-04-18T05:27:19.213706Z","shell.execute_reply":"2025-04-18T05:27:19.222792Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# The maybe_route_to_tools Function: Dynamic Conversation Routing\n\nThis function serves as the central traffic controller for the BaristaBot conversation flow, determining where to route the conversation based on the current state.\n\n## Function Purpose\nThe function analyzes the current conversation state and dynamically decides where to route the flow next. It examines the last message and routes to the appropriate node based on the message content and order status.\n\n## Routing Logic Breakdown\n1. **Initial Validation**\n   - Checks if messages exist in the state\n   - Raises an error if no messages are found\n   - Retrieves the last message for analysis\n\n2. **Exit Condition Check**\n   - Checks if the order has been completed (state.finished is True)\n   - Returns the special END constant to terminate the conversation\n   - Relies on the AI's system instructions to provide a proper goodbye message\n\n3. **Tool Call Detection**\n   - Checks if the message contains tool calls (AI requesting to use tools)\n   - Distinguishes between two types of tools:\n     - Automated tools (menu-related): Routes to the \"tools\" node\n     - Order management tools: Routes to the \"ordering\" node\n   - This separation allows different handling for information retrieval vs. state-changing operations\n\n4. **Default Human Interaction**\n   - If no special routing is needed, routes to the \"human\" node\n   - This allows the human user to respond to the AI's message\n\n## In the LangGraph Context\nThis function is used as a conditional edge in the state graph. The dynamic routing creates a conversation flow that allows BaristaBot to:\n- Retrieve menu information when needed\n- Manage the order state properly\n- Interact with the user naturally\n- Exit gracefully when the order is complete\n\nThis routing mechanism enables the conversation to flow naturally between different components while maintaining appropriate state transitions throughout the ordering process.","metadata":{}},{"cell_type":"code","source":"def maybe_route_to_tools(state: OrderState) -> str:\n    \"\"\"Route between chat and tool nodes if a tool call is made.\"\"\"\n    if not (msgs := state.get(\"messages\", [])):\n        raise ValueError(f\"No messages found when parsing state: {state}\")\n\n    msg = msgs[-1]\n\n    if state.get(\"finished\", False):\n        # When an order is placed, exit the app. The system instruction indicates\n        # that the chatbot should say thanks and goodbye at this point, so we can exit\n        # cleanly.\n        return END\n\n    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n        # Route to `tools` node for any automated tool calls first.\n        if any(\n            tool[\"name\"] in tool_node.tools_by_name.keys() for tool in msg.tool_calls\n        ):\n            return \"tools\"\n        else:\n            return \"ordering\"\n\n    else:\n        return \"human\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:24.976126Z","iopub.execute_input":"2025-04-18T05:27:24.977191Z","iopub.status.idle":"2025-04-18T05:27:24.983756Z","shell.execute_reply.started":"2025-04-18T05:27:24.977149Z","shell.execute_reply":"2025-04-18T05:27:24.982533Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# The chatbot_with_tools Function: Core LLM Interaction Node\n\n## Function Purpose\nThis function serves as the primary interaction point with the language model in the BaristaBot conversation system. It processes the current state, generates AI responses, and maintains conversation continuity.\n\n## Key Features\n\n1. **State Handling**\n   * Receives the current OrderState containing conversation history and order details\n   * Establishes default values for \"order\" and \"finished\" to ensure state consistency\n   * Returns an updated state with new AI messages\n\n2. **Response Generation Logic**\n   * For ongoing conversations: Invokes the language model with both system instructions and conversation history\n   * For new conversations: Creates an initial welcome message\n   * Uses tool-enhanced LLM (llm_with_tools) that has access to menu and ordering functions\n\n## State Management\n* Preserves existing state properties while updating only the \"messages\" field\n* Uses Python's dictionary merging (| operator) to combine defaults, current state, and new messages\n* Ensures the state structure remains consistent throughout the conversation flow\n\n## In the LangGraph Context\nThis function operates as a node in the state graph that:\n* Processes incoming conversation state\n* Generates appropriate AI responses with tool capabilities\n* Maintains state consistency throughout the conversation\n* Acts as the primary interface between the user and the ordering system's intelligence","metadata":{}},{"cell_type":"code","source":"def chatbot_with_tools(state: OrderState) -> OrderState:\n    \"\"\"The chatbot with tools. A simple wrapper around the model's own chat interface.\"\"\"\n    defaults = {\"order\": [], \"finished\": False}\n\n    if state[\"messages\"]:\n        new_output = llm_with_tools.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n    else:\n        new_output = AIMessage(content=WELCOME_MSG)\n\n    # Set up some defaults if not already set, then pass through the provided state,\n    # overriding only the \"messages\" field.\n    return defaults | state | {\"messages\": [new_output]}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:29.695415Z","iopub.execute_input":"2025-04-18T05:27:29.695849Z","iopub.status.idle":"2025-04-18T05:27:29.701853Z","shell.execute_reply.started":"2025-04-18T05:27:29.695813Z","shell.execute_reply":"2025-04-18T05:27:29.700741Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# The evaluator_node Function: Quality Control for BaristaBot Responses\n\nThis function implements an AI-powered quality assurance system that checks and potentially improves BaristaBot's responses before they reach the customer:\n\n## Function Purpose\nThe evaluator_node function serves as a quality control checkpoint that intercepts and evaluates every AI-generated response before it reaches the customer. It uses the same LLM technology to evaluate and improve BaristaBot's responses, ensuring they meet quality standards.\n\n## Implementation Details\n\n1. **Selective Evaluation**\n   * Only processes states that contain messages\n   * Only evaluates messages from the AI (ignores user messages)\n   * Returns the state unchanged if there's nothing to evaluate\n\n2. **Evaluation System**\n   * Uses the same Google Gemini model for evaluation (\"gemini-2.0-flash\")\n   * Creates a specialized evaluation prompt with specific quality criteria\n   * The evaluation system acts as a \"second opinion\" on the AI's initial response\n\n3. **Quality Criteria**\n   The evaluator checks if the response:\n   * Correctly follows menu options - Ensures accuracy about available items\n   * Uses appropriate tools - Verifies proper use of order management functions\n   * Stays on-topic - Maintains focus on cafe-related conversation\n   * Is helpful and clear - Ensures customer-friendly communication\n\n4. **Correction Mechanism**\n   * If the evaluator returns \"GOOD\", the original response passes through unchanged\n   * If corrections are needed, the evaluator provides a fixed version\n   * The function cleans up any meta-text like \"Corrected Text:\" prefixes\n   * Creates a new message with the corrected content\n   * Preserves any tool calls from the original message (important for function execution)\n   * Updates the state with the corrected message\n\n## System Architecture Impact\n\nThis evaluation node adds a critical layer of reliability to the BaristaBot by:\n* Reducing errors - Catching and correcting mistakes before they reach customers\n* Ensuring consistency - Maintaining accurate information about menu items\n* Improving customer experience - Delivering clearer, more helpful responses\n* Preserving functionality - Maintaining tool calls even when content is corrected\n\nThe node demonstrates a powerful pattern in LLM-based applications where one AI system (the evaluator) reviews and improves the output of another (the primary chatbot), creating a more robust customer-facing experience.","metadata":{}},{"cell_type":"code","source":"def evaluator_node(state):\n    \"\"\"\n    Evaluator that checks BaristaBot responses before they reach the user.\n    Simply evaluates and potentially improves responses.\n    \"\"\"\n    # Only evaluate if there are messages\n    if not state.get(\"messages\", []):\n        return state\n    \n    # Get the last message\n    last_msg = state[\"messages\"][-1]\n    \n    # Only evaluate AI messages (from the bot)\n    if not isinstance(last_msg, AIMessage):\n        return state\n    \n    # Create evaluator using the same model\n    eval_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n    \n    # Create evaluation prompt\n    eval_prompt = [\n        (\"system\", \"\"\"\n        You are evaluating a cafe ordering chatbot response. Check if the response:\n        1. Correctly follows the menu options\n        2. Uses appropriate tools for ordering\n        3. Stays on-topic about cafe items only\n        4. Is helpful and clear for customers\n        \n        If the response is good, return \"GOOD\".\n        If the response needs correction, provide ONLY the corrected text without any prefix.\n        Do not include phrases like \"Corrected Text:\" in your response.\n        \"\"\"),\n        (\"user\", f\"Evaluate this BaristaBot response: {last_msg.content}\")\n    ]\n    \n    # Get evaluation\n    evaluation = eval_model.invoke(eval_prompt)\n    \n    # Apply corrections if needed\n    if not evaluation.content.startswith(\"GOOD\"):\n        # Process the corrected content to remove any unwanted prefixes\n        corrected_content = evaluation.content\n        if \"Corrected Text:\" in corrected_content:\n            corrected_content = corrected_content.replace(\"Corrected Text:\", \"\").strip()\n            \n        # Create corrected message\n        corrected_msg = AIMessage(content=corrected_content)\n        \n        # Preserve tool calls if present\n        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n            corrected_msg.tool_calls = last_msg.tool_calls\n        \n        # Replace the message\n        return {**state, \"messages\": state[\"messages\"][:-1] + [corrected_msg]}\n    \n    # No changes needed\n    return state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:32.840908Z","iopub.execute_input":"2025-04-18T05:27:32.841344Z","iopub.status.idle":"2025-04-18T05:27:32.850203Z","shell.execute_reply.started":"2025-04-18T05:27:32.841303Z","shell.execute_reply":"2025-04-18T05:27:32.849072Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Building the BaristaBot Graph: Defining Nodes and Connections\n\nThis code creates the conversation flow structure for the BaristaBot application using LangGraph's state graph architecture.\n\n## Tool Organization and Binding\n\nThe code organizes the BaristaBot's tools into two distinct categories:\n\n1. **Informational Tools** (`auto_tools`):\n   * `get_menu`: Retrieves the full menu\n   * `search_menu`: Searches for specific menu information\n   * These tools are wrapped in a ToolNode for automatic handling\n\n2. **Order Management Tools** (`order_tools`):\n   * Tools that modify the order state (add, confirm, get, clear, place)\n   * These require custom implementation in the `order_node`\n\nAll tools are bound to the language model with `llm.bind_tools()`, making them available for the LLM to call during conversation.\n\n## Graph Node Definition\n\nThe code defines five specialized nodes in the conversation graph:\n\n* **\"chatbot\"**: Generates AI responses using the tool-enabled LLM\n* **\"human\"**: Captures and processes user input\n* **\"tools\"**: Handles informational tool execution\n* **\"ordering\"**: Implements order state management\n* **\"evaluator\"**: Quality-checks AI responses before they reach the user\n\n## Connection and Flow Definition\n\nThe connections between nodes define the possible paths through the conversation:\n\n### Quality Control Flow\n* AI responses always flow through the evaluator first (chatbot  evaluator)\n* The evaluator then routes to appropriate nodes based on message content\n\n### Dynamic Routing\n* `maybe_route_to_tools` determines where to route based on message content\n* `maybe_exit_human_node` checks if the user wants to exit\n\n### Tool Processing Loops\n* Both tool types route back to the chatbot after execution\n* This creates conversation loops for order building\n\n### Conversation Entry Point\n* The graph begins at the chatbot node (START  chatbot)\n\n## Compilation\nThe `compile()` method creates the executable workflow.\n\nThis architecture creates a flexible conversation flow that dynamically adapts based on user input and AI responses, while maintaining proper state management throughout the ordering process.","metadata":{}},{"cell_type":"code","source":"# Define the tools and create a \"tools\" node.\nauto_tools = [get_menu, search_menu]\ntool_node = ToolNode(auto_tools)\norder_tools = [add_to_order, confirm_order, get_order, clear_order, place_order]\nllm_with_tools = llm.bind_tools(auto_tools + order_tools)\n\ngraph_builder = StateGraph(OrderState)\n\n# Nodes\ngraph_builder.add_node(\"chatbot\", chatbot_with_tools)\ngraph_builder.add_node(\"human\", human_node)\ngraph_builder.add_node(\"tools\", tool_node)\ngraph_builder.add_node(\"ordering\", order_node)\ngraph_builder.add_node(\"evaluator\", evaluator_node)\n\n# Chatbot -> {ordering, tools, human, END}\n# 3. Add a simple edge from chatbot to evaluator\ngraph_builder.add_edge(\"chatbot\", \"evaluator\")\n# 3. Connect evaluator to same destinations as chatbot originally went to\ngraph_builder.add_conditional_edges(\"evaluator\", maybe_route_to_tools)\n# Human -> {chatbot, END}\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n\n# Tools (both kinds) always route back to chat afterwards.\ngraph_builder.add_edge(\"tools\", \"chatbot\")\ngraph_builder.add_edge(\"ordering\", \"chatbot\")\n\ngraph_builder.add_edge(START, \"chatbot\")\ngraph_with_order_tools = graph_builder.compile()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:38.082845Z","iopub.execute_input":"2025-04-18T05:27:38.083269Z","iopub.status.idle":"2025-04-18T05:27:38.126459Z","shell.execute_reply.started":"2025-04-18T05:27:38.083216Z","shell.execute_reply":"2025-04-18T05:27:38.125378Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Application Execution: Starting the BaristaBot\n\nThis single line of code represents the execution entry point for the entire BaristaBot application:\n\n```python\nstate = graph_with_order_tools.invoke({\"messages\": []}, config)\n```\n\n## What This Line Does\n\nThis compact but powerful line of code:\n\n### Initializes the Conversation:\n- Starts with an empty message list `{\"messages\": []}`\n- The empty initial state serves as a blank slate for the conversation\n\n### Triggers the Conversation Flow:\n- Invokes the compiled state graph (`graph_with_order_tools`)\n- Starts at the designated START node (which routes to \"chatbot\")\n- Executes the welcome message generation\n\n### Configures Runtime Behavior:\n- Applies the config settings (defined earlier as `{\"recursion_limit\": 100}`)\n- The recursion limit of 100 allows for complex, multi-turn conversations\n- This prevents infinite loops while supporting lengthy ordering processes\n\n### Returns the Final State:\n- After the conversation completes, the final state is stored in the `state` variable\n- This contains the complete order and conversation history\n\n## Execution Flow\n\nWhen this line runs:\n1. The chatbot node generates the welcome message\n2. The evaluator checks the message quality\n3. Control passes to the human node for user input\n4. Based on user responses, the flow navigates through various nodes\n5. The conversation continues until either:\n   - The user enters an exit command\n   - An order is successfully placed\n\nThis single line effectively sets in motion the entire conversation loop, with the state being continuously updated and passed between nodes as the interaction progresses.","metadata":{}},{"cell_type":"code","source":"state = graph_with_order_tools.invoke({\"messages\": []}, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:43.103010Z","iopub.execute_input":"2025-04-18T05:27:43.103422Z","iopub.status.idle":"2025-04-18T05:27:46.476133Z","shell.execute_reply.started":"2025-04-18T05:27:43.103383Z","shell.execute_reply":"2025-04-18T05:27:46.474959Z"}},"outputs":[{"name":"stdout","text":"Model: Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  q\n"}],"execution_count":20},{"cell_type":"code","source":"pprint(state[\"order\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T05:27:51.715401Z","iopub.execute_input":"2025-04-18T05:27:51.715792Z","iopub.status.idle":"2025-04-18T05:27:51.721398Z","shell.execute_reply.started":"2025-04-18T05:27:51.715761Z","shell.execute_reply":"2025-04-18T05:27:51.720326Z"}},"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}